{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:80/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [10/Aug/2023 23:04:40] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:04:40] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:04:43] \"GET /pywebio HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:04:46] \"GET /pywebio HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:07:17] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:07:24] \"GET /pywebio HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [10/Aug/2023 23:07:34] \"GET /pywebio HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "from pywebio.input import *\n",
    "from pywebio.output import *\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "import time\n",
    "from pywebio.platform.flask import webio_view\n",
    "from pywebio import STATIC_PATH\n",
    "from flask import Flask, send_from_directory\n",
    "app = Flask(__name__)\n",
    "\n",
    "df = pd.read_csv('travel_destinations.csv')\n",
    "cities = list(df['City'])\n",
    "description = list(df['description'])\n",
    "\n",
    "# Dictionary to map index to travel destination\n",
    "index_destination_dict = {}\n",
    "for i in range(len(df)):\n",
    "    index_destination_dict[i] = df.loc[i]['City']\n",
    "index_destination_dict\n",
    "\n",
    "# Dictionary to map travel destination to index\n",
    "destination_index_dict = {}\n",
    "for i in range(len(df)):\n",
    "    destination_index_dict[df.loc[i]['City']] = i\n",
    "destination_index_dict\n",
    "\n",
    "df1 = pd.read_csv('destinations_with_processed_text.csv')\n",
    "corpus = df1['processed_text']\n",
    "\n",
    "\n",
    "def previously_visited_destination(previously_visited_travel_destination):\n",
    "    df2 = pd.read_csv('destinations_with_processed_text.csv')\n",
    "    corpus = df2['processed_text']\n",
    "    tv = TfidfVectorizer()\n",
    "    X = tv.fit_transform(corpus)\n",
    "    vectors = X.toarray()\n",
    "    correlationMatrix = sigmoid_kernel(vectors, vectors)\n",
    "    \n",
    "    idx = destination_index_dict[str(previously_visited_travel_destination)]\n",
    "    similarity_list = correlationMatrix[idx]\n",
    "    lst = []\n",
    "    for i in range(len(similarity_list)):\n",
    "        lst.append((similarity_list[i], i))\n",
    "    return sorted(lst, reverse = True)\n",
    "    \n",
    "def free_text_based_query():\n",
    "    free_text = textarea('Enter a free text', rows = 3, placeholder = 'Write anything...\\n\\'snow winter nature trekking\\' ... \\'lake boating waterfall tiger\\' ... \\'market clothes nights history\\' ... \\'beach cruise camping boats ships\\' ... \\'temples hills altitude winter line\\' ... \\'lion safari forests camping nature\\' ... ')\n",
    "    number_of_recommendations = input(\"Enter the number of recommendations\", type = NUMBER)\n",
    "    \n",
    "    #Remove Hyperlinks\n",
    "    processed_query = re.sub(r\"http\\S+\", ' ', str(free_text))   \n",
    "    #processed_query = re.sub(r'https?:\\/\\/\\S*', '', query, flags=re.MULTILINE)\n",
    "\n",
    "    #Remove Punctuation Marks and Special Symbols\n",
    "    processed_query = re.sub('[^a-zA-Z0-9]', ' ', processed_query)\n",
    "\n",
    "    #Lowercase\n",
    "    processed_query = processed_query.lower()\n",
    "\n",
    "    #Create a list of strings using string.split() method\n",
    "    processed_query = processed_query.split()\n",
    "    \n",
    "    wl = WordNetLemmatizer()\n",
    "    # Prefer Lemmatization over Stemming\n",
    "    #processed_query = [ps.stem(word) for word in processed_query if not word in stopwords.words('english')]\n",
    "    processed_query = [wl.lemmatize(word, pos='v') for word in processed_query if not word in stopwords.words('english')]    \n",
    "    processed_query = ' '.join(processed_query)\n",
    "    # corpus.append(processed_query)\n",
    "    # print(i, end = ' ')\n",
    "    \n",
    "    new_corpus = []\n",
    "    for desc in corpus:\n",
    "        new_corpus.append(desc)\n",
    "    new_corpus.append(processed_query)\n",
    "    #new_corpus\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cv = CountVectorizer()\n",
    "    new_X = cv.fit_transform(new_corpus)\n",
    "    new_vectors = new_X.toarray()\n",
    "    \n",
    "    from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "    new_correlationMatrix = sigmoid_kernel(new_vectors, new_vectors)\n",
    "    #print(new_correlationMatrix)\n",
    "    \n",
    "    list_of_tuples = []\n",
    "    for i in range(len(df)):\n",
    "        list_of_tuples.append((new_correlationMatrix[-1][i], i))\n",
    "    \n",
    "    recommendation_list = []\n",
    "    for element in sorted(list_of_tuples, reverse = True):\n",
    "        recommendation_list.append(index_destination_dict[element[1]])\n",
    "    final_rec = recommendation_list[:int(number_of_recommendations)]\n",
    "    for rec in final_rec:\n",
    "        put_html('<hr>')\n",
    "        put_markdown(\"# *`%s`*\" % rec)\n",
    "        pic = 'DestinationPics/' + str(rec) + '.jpg'\n",
    "        img = open(pic, 'rb').read()\n",
    "        put_image(img, width='100%')\n",
    "        \n",
    "\n",
    "def select_recommendation_system():\n",
    "    recommendation_system = select('Which type of recommendation system would you prefer?', ['Recommendation based on free text-based query', 'Recommendations similar to previously visited destination'])\n",
    "    if(recommendation_system == 'Recommendation based on free text-based query'):\n",
    "        free_text_based_query()\n",
    "    if(recommendation_system == 'Recommendations similar to previously visited destination'):\n",
    "        previously_visited_travel_destination = select('Select the previously visited travel destination', cities)\n",
    "        recommendations_list = previously_visited_destination(previously_visited_travel_destination)\n",
    "        number_of_recommendations = input(\"Enter the number of recommendations\", type = NUMBER)\n",
    "        for element in recommendations_list[:number_of_recommendations]:\n",
    "            put_markdown(\"# *`%s`*\" % index_destination_dict[element[1]])\n",
    "            pic = 'DestinationPics/' + str(index_destination_dict[element[1]]) + '.jpg'\n",
    "            img = open(pic, 'rb').read()\n",
    "            put_image(img, width='100%')\n",
    "\n",
    "def explore():\n",
    "    put_markdown('## Please wait! Your request is being processed!')\n",
    "    \n",
    "    #Display Processbar\n",
    "    put_processbar('bar');\n",
    "    for i in range(1, 11):\n",
    "        set_processbar('bar', i / 10)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    #Display the Travel Destination along with Description\n",
    "    for i in range(len(df)):\n",
    "        put_html('<hr>')\n",
    "        put_markdown(\"# *`%s`*\" % cities[i])\n",
    "        pic = 'DestinationPics/' + str(cities[i]) + '.jpg'\n",
    "        img = open(pic, 'rb').read()\n",
    "        put_image(img, width='100%')\n",
    "        #temp = description[i].replace('-', ' ')\n",
    "        #put_text(\"     %s\" % temp)\n",
    "    put_markdown(\"# *In case of copyright issues, please drop an email to `rishabh20118@iiitd.ac.in`*\")\n",
    "    img = open('DestinationPics/India_1.jpg', 'rb').read()\n",
    "    put_image(img, width='1500px')\n",
    "\n",
    "def choices():\n",
    "    img = open('DestinationPics/DesiSafar Logo.jpg', 'rb').read()\n",
    "    put_image(img, width='900px')\n",
    "    put_markdown('# **Travel Destination Recommendation System**')\n",
    "    answer = radio(\"Choose one\", options=['Explore Incredible India!', 'Get Travel Recommendations'])\n",
    "    if(answer == 'Explore Incredible India!'):\n",
    "        explore()\n",
    "    if(answer == 'Get Travel Recommendations'):\n",
    "        put_text('\\nLet\\'s get started! ')\n",
    "        select_recommendation_system()\n",
    "\n",
    "app.add_url_rule('/desisafar', 'webio_view', webio_view(choices), methods=['GET', 'POST', 'OPTIONS'])\n",
    "app.run(host='localhost', port=80)\n",
    "#app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
